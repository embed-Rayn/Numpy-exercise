{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. 퍼셉트론(Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AND(x1, x2):\n",
    "    input_x = np.array([x1, x2, 1])\n",
    "    w=np.array([[0.6], [0.6], [-1]])\n",
    "    res = np.matmul(input_x, w)\n",
    "    if res > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False False True\n"
     ]
    }
   ],
   "source": [
    "print(AND(0, 0), AND(0, 1), AND(1, 0), AND(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OR(x1, x2):\n",
    "    input_x = np.array([x1, x2, 1])\n",
    "    w=np.array([[1], [1], [-0.9]])\n",
    "    res = np.matmul(input_x, w)\n",
    "    if res > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True True True\n"
     ]
    }
   ],
   "source": [
    "print(OR(0, 0), OR(0, 1), OR(1, 0), OR(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. XOR 문제 - 단층 퍼셉트론 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLP(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, 1),\n",
    "            nn.Sigmoid()).to(device)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        prediction = self.model(X)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0/20000\t cost: 0.727397\n",
      "1000/20000\t cost: 0.695188\n",
      "2000/20000\t cost: 0.693817\n",
      "3000/20000\t cost: 0.693379\n",
      "4000/20000\t cost: 0.693232\n",
      "5000/20000\t cost: 0.693180\n",
      "6000/20000\t cost: 0.693160\n",
      "7000/20000\t cost: 0.693153\n",
      "8000/20000\t cost: 0.693150\n",
      "9000/20000\t cost: 0.693148\n",
      "10000/20000\t cost: 0.693148\n"
     ]
    }
   ],
   "source": [
    "model = OLP(device)\n",
    "nb_epochs = 10000\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    h = model.forward(X)\n",
    "    #print(h), print(Y)\n",
    "    cost = torch.nn.functional.binary_cross_entropy(h, Y)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        print(\"{:4d}/{}\\t cost: {:.6f}\".format(epoch, nb_epochs, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 출력값(Hypothesis):  [[0.50076187]\n",
      " [0.5002598 ]\n",
      " [0.49997926]\n",
      " [0.4994772 ]]\n",
      "모델의 예측값(Predicted):  [[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "실제값(Y):  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도(Accuracy):  0.5\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hypothesis = model.forward(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    acc = (predicted == Y).float().mean()\n",
    "    print('모델의 출력값(Hypothesis): ', hypothesis.detach().cpu().numpy())\n",
    "    print('모델의 예측값(Predicted): ', predicted.detach().cpu().numpy())\n",
    "    print('실제값(Y): ', Y.cpu().numpy())\n",
    "    print('정확도(Accuracy): ', acc.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. XOR 문제 - 다층 퍼셉트론 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, 10, bias = True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(10, 10, bias = True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(10, 1, bias = True),\n",
    "            nn.Sigmoid()).to(device)\n",
    "    def forward(self, X):\n",
    "        return self.model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0/20000: \t0.727315\n",
      " 1000/20000: \t0.023630\n",
      " 2000/20000: \t0.001834\n",
      " 3000/20000: \t0.000845\n",
      " 4000/20000: \t0.000533\n",
      " 5000/20000: \t0.000384\n",
      " 6000/20000: \t0.000297\n",
      " 7000/20000: \t0.000242\n",
      " 8000/20000: \t0.000203\n",
      " 9000/20000: \t0.000175\n",
      "10000/20000: \t0.000153\n",
      "11000/20000: \t0.000136\n",
      "12000/20000: \t0.000122\n",
      "13000/20000: \t0.000111\n",
      "14000/20000: \t0.000101\n",
      "15000/20000: \t0.000093\n",
      "16000/20000: \t0.000086\n",
      "17000/20000: \t0.000080\n",
      "18000/20000: \t0.000075\n",
      "19000/20000: \t0.000070\n",
      "20000/20000: \t0.000066\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "nb_epochs = 20000\n",
    "#optimizer = torch.opitm.SGD(model.parameters(), lr = 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    h = model.forward(X)\n",
    "    cost = nn.functional.binary_cross_entropy(h, Y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 1000 == 0:\n",
    "        print(\"{:5d}/{}: \\t{:6f}\".format(epoch, nb_epochs, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 출력값(Hypothesis):  [[4.2741802e-05]\n",
      " [9.9992466e-01]\n",
      " [9.9993110e-01]\n",
      " [7.8007783e-05]]\n",
      "모델의 예측값(Predicted):  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "실제값(Y):  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도(Accuracy):  1.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hypothesis = model.forward(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    acc = (predicted == Y).float().mean()\n",
    "    print('모델의 출력값(Hypothesis): ', hypothesis.detach().cpu().numpy())\n",
    "    print('모델의 예측값(Predicted): ', predicted.detach().cpu().numpy())\n",
    "    print('실제값(Y): ', Y.cpu().numpy())\n",
    "    print('정확도(Accuracy): ', acc.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. 다층 퍼셉트론으로 손글씨 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # 시각화를 위한 맷플롯립\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits() # 1,979개의 이미지 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(digits.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(digits.target[0:10])\n",
    "print(digits.keys())\n",
    "print(digits.target_names[0:10])\n",
    "#print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 1797\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수 : {}'.format(len(digits.images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:5]): # 5개의 샘플만 출력\n",
    "    plt.subplot(2, 5, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('sample: {}'.format(label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.data # 이미지. 즉, 특성 행렬\n",
    "Y = digits.target # 각 이미지에 대한 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 다층 퍼셉트론 분류기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNDigit(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 10),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        return self.model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0/ 10000: cost:2.309320\n",
      " 2000/ 10000: cost:1.462120\n",
      " 4000/ 10000: cost:1.462105\n",
      " 6000/ 10000: cost:1.462103\n",
      " 8000/ 10000: cost:1.462101\n",
      "10000/ 10000: cost:1.462100\n"
     ]
    }
   ],
   "source": [
    "model = NNDigit()\n",
    "nb_epochs = 100\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "X = torch.FloatTensor(X).view(-1, 64)\n",
    "Y = torch.LongTensor(Y)\n",
    "for epoch in range(nb_epochs+1):\n",
    "    h = model.forward(X)\n",
    "    #cost = nn.CrossEntropyLoss(h, Y)\n",
    "    cost = torch.nn.functional.cross_entropy(h,Y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(csot.item())\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"{:5d}/ {}: cost:{:6f}\".format(epoch, nb_epochs, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9988870620727539\n",
      "Label:  8\n",
      "Prediction:  8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "with torch.no_grad(): # torch.no_grad()를 하면 gradient 계산을 수행하지 않는다.\n",
    "    X_test = X\n",
    "    Y_test = Y\n",
    "\n",
    "    prediction = model.forward(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # MNIST 테스트 데이터에서 무작위로 하나를 뽑아서 예측을 해본다\n",
    "    r = random.randint(0, len(X_test) - 1)\n",
    "    X_single_data = X_test[r:r + 1].view(-1, 64).float().to(device)\n",
    "    Y_single_data = Y_test[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = model.forward(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "    plt.imshow(X_test[r:r + 1].view(8,8), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
